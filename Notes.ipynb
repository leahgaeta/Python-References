{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toolbox Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'zip'>\n"
     ]
    }
   ],
   "source": [
    "#using zip(); zip() function accepts arbitrary number of iterables and returns an iterator of tuples\n",
    "avengers = ['hawkeye', 'iron man', 'thor', 'quicksilver']\n",
    "names = ['barton', 'stark', 'odinson', 'maximoff']\n",
    "z = zip(avengers, names) #creates a zip object which is an iterator of tuples\n",
    "print(type(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hawkeye', 'barton'), ('iron man', 'stark'), ('thor', 'odinson'), ('quicksilver', 'maximoff')]\n"
     ]
    }
   ],
   "source": [
    "#using zip() cont'd\n",
    "print(list(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function\n",
    "def raise_both(value1, value2):  #function header\n",
    "    \"\"\"Raise value1 to the power of value2 and vice versa.\"\"\"  #doc strings\n",
    "    \n",
    "    new_value1 = value1 ** value2  #function body\n",
    "    new_value2 = value2 ** value1\n",
    "    \n",
    "    new_tuple = (new_value1, new_value2)\n",
    "    \n",
    "    return new_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining a function example\n",
    "raise_both(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Comprehension\n",
    "\n",
    "Basic\n",
    "[output expression for iterator variable in iterable]\n",
    "\n",
    "Advanced\n",
    "[output expression + conditional on output for iterator variable in iterable + conditional on iterable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a generator function\n",
    "def num_sequence(n): #generator function that when called with the number n produces a generator object that generates \n",
    "    #integers 0 through n\n",
    "    \"\"\"Generate values from 0 to n.\"\"\"\n",
    "    i = 0 #i is initalized to 0 and first time function is called it yields i = 0\n",
    "    while i < n:\n",
    "        yield i\n",
    "        i += 1 #then adds 1 to i and will yield 1 on the next iteration and so on\n",
    "#the while loop is true until i = n and then the generator ceases to yield values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a text file\n",
    "\n",
    "    filename = 'huck_finn.txt'  #assign the filename to a variable as a string\n",
    "\n",
    "    file = open(filename, mode = 'r')  #pass filename to function open and also pass argument mode = r which makes sure can only read it, not write to it, if wanted to write then mode = w\n",
    "\n",
    "    text = file.read() #assign the text from the file to a variable text by applying method read to the connection to the file\n",
    "\n",
    "    file.close()  #then close connection to file\n",
    "\n",
    "    print(text)  #to read\n",
    "\n",
    "\n",
    "Or best practice is to use WITH -- then don't have to worry about closing\n",
    "\n",
    "    with open('huck_finn.txt', 'r') as file:\n",
    "\n",
    "        print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Flat Files Using NumPy\n",
    "\n",
    "    import numpy as np\n",
    "    filename = 'MNIST.txt'\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=str)  #delimiter can be whitespace too or tab-delimited '\\t' so needs to be specified, dtype is to load it all in as strings (but probably wouldn't want to use for mixed data types)\n",
    "    \n",
    "Often will need to import datasets with different datatypes in different columns, so can use np.genfromtxt() instead and pass dtype=None to figure out what data types each column should be, and names=True means there's a header\n",
    "    \n",
    "    data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Using Pandas -- best practice!\n",
    "\n",
    "    import pandas as pd\n",
    "    filename = 'winequality-red.csv'\n",
    "    data = pd.read_csv(filename)\n",
    "    data.head()\n",
    "    data_array = data.values #if want to convert into numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled Files\n",
    "\n",
    "    import pickle\n",
    "    with open('pickled_fruit.pkl', 'rb') as file: #read only & binary file\n",
    "        data = pickle.load(file)\n",
    "    print(data)\n",
    "    ['peaches': 13, 'apples': 4, 'oranges': 11}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Excel Spreadsheets\n",
    "\n",
    "    import pandas as pd\n",
    "    file = 'urbanpop.xlsx'\n",
    "    data = pd.ExcelFile(file)\n",
    "    print(data.sheet_names)\n",
    "    ['1960-1966', '1967-1974', '1975-2011']\n",
    "    df1 = data.parse('1960-1966') #sheet name, as string\n",
    "    df2 = data.parse(0) #sheet index, as float\n",
    "    df3 = data.parse(___, skiprows=___, names=___, parse_cols=___) #skips rows, names columns, designates which columns to parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring Current Working Directory\n",
    "\n",
    "    import os          #this imports library os\n",
    "    wd = os.getcwd()   #this stores the name of current directory in string called wd\n",
    "    os.listdir(wd)     #outputs the contents of the directory in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAS and Stata Files\n",
    "\n",
    "    SAS: Statistical Analysis Systems    #used in business analytics & biostatistics\n",
    "    Stata: \"Statistics\" + \"data\"         #academic social sciences research\n",
    "\n",
    "\n",
    "Importing SAS Files\n",
    "\n",
    "    import pandas as pd\n",
    "    from sas7bdat import SAS7BDAT\n",
    "    with SAS7BDAT('urbanpop.sas7bdat') as file:\n",
    "        df_sas = file.to_data_frame()\n",
    "\n",
    "\n",
    "Importing Stata Files\n",
    "\n",
    "    import pandas as pd\n",
    "    data = pd.read_stata('urbanpop.dta')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 Files\n",
    "\n",
    "    Heirarchical Data Format version 5\n",
    "    Standard for storing large quantities of numeric data\n",
    "    Datasets can be hundreds of gigabytes or terabytes\n",
    "    HDF5 can scale to exabytes\n",
    "\n",
    "Importing HDF5 Files\n",
    "\n",
    "    import h5py\n",
    "    filename = 'H-H1_LOSC_4_V1-815411200-4096.hdf5'\n",
    "    data = h5py.File(filename, 'r')        # 'r' is to read\n",
    "    print(type(data))\n",
    "    <class 'h5py._hl.files.File'>\n",
    "    \n",
    "    for key in data.keys():\n",
    "        print(key)                         # there are three keys, each is an HDF group\n",
    "    meta                                   # meta-data for file, basic info such as GPS times covered\n",
    "    quality                                # refers to data quality\n",
    "    strain                                 # strain data, main measurements\n",
    "    \n",
    "    print(type(data['meta']))\n",
    "    <class 'h5py._hl.group.Group'>\n",
    "    \n",
    "    for key in data['meta'].keys():\n",
    "        print(key)\n",
    "    Description\n",
    "    DescriptionURL\n",
    "    Detector\n",
    "    ...\n",
    "    \n",
    "    print(data['meta']['Description'].value, data['meta']['Detector'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATLAB\n",
    "\n",
    "    \"Matrix Laboratory\"\n",
    "    Industry standard in engineering and science\n",
    "    Powerful linear algebra and matrix capabilities\n",
    "    Data saved as .mat files (use scipy)\n",
    "\n",
    "Importing a .mat file\n",
    "\n",
    "    import scipy.io\n",
    "    filename = 'workspace.mat'\n",
    "    mat = scipy.io.loadmat(filename)\n",
    "    print(type(mat))\n",
    "    <class 'dict'>\n",
    "                    # get a dictionary where\n",
    "                    # keys = MATLAB variable names\n",
    "                    # values = objects assigned to variables\n",
    "    print(type(mat['x']))\n",
    "    <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Relational Databases\n",
    "\n",
    "    Tables are linked, ex. orders table with links to employees table and customers table\n",
    "    Call this the \"relational model\" -- widely adopted\n",
    "    Todd's 12 Rules/Commandments (actually consists of 13 rules since zero-indexed!)\n",
    "        Describes what a Relational Database Management System should adhere to to be considered relational\n",
    "        Examples: PostgreSQL, MySQL, SQLite ... all use SQL\n",
    "        SQL = Structured Query Language ... which describes how you communicate with a database in order to both \n",
    "            access and update the information it contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Database Engine - Example\n",
    "\n",
    "    from sqlalchemy import create_engine                     # use SQLAlchemy package to access SQL database\n",
    "    engine = create_engine('sqlite:///Northwind.sqlite')     # use SQLite database, which is fast and simple\n",
    "    table_names = engine.table_names()                       # to get table names\n",
    "    print(table_names)\n",
    "    ['Categories', 'Customers', 'EmployeeTerritories', 'Employees']\n",
    "                                Note: 'sqlite:///Northwind.sqlite' is called the connection string to the SQLite \n",
    "                                Database called Northwind.sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying Relational Databases in Python\n",
    "\n",
    "    Basic SQL query\n",
    "    \n",
    "    SELECT * FROM Table_Name                                 # this returns all columns of all rows of the table\n",
    "    \n",
    "    Workflow of SQL querying\n",
    "        - import packages & functions\n",
    "        - create the database engine\n",
    "        - connect to the engine\n",
    "        - query the database\n",
    "        - save query results to a DataFrame\n",
    "        - close the connection\n",
    "\n",
    "    from sqlalchemy import create_engine\n",
    "    import pandas as pd\n",
    "    engine = create_engine('sqlite:///Northwind.sqlite')     # create the engine\n",
    "    con = engine.connect()                                   # create the connection object con\n",
    "    rs = con.execute(\"SELECT * FROM Orders\")                 # to query the database\n",
    "    df = pd.DataFrame(rs.fetchall())                         # turns it into a DataFrame, fetchall fetches all rows\n",
    "    df.columns = rs.keys()                                   # this sets the DataFrame column names\n",
    "    con.close()                                              # close the connection, don't forget!\n",
    "    \n",
    "    Can also use the context manager so don't have to worry about closing a connection\n",
    "        from sqlalchemy import create_engine\n",
    "        import pandas as pd\n",
    "        engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "        with engine.connect() as con:\n",
    "            rs = con.execute(\"SELECT OrderID, OrderDate, ShipName FROM Orders\")  # no *(means select all columns)\n",
    "            df = pd.DataFrame(rs.fetchmany(size = 5))        # instead of fetchall, imports 5 rows\n",
    "            df.columns = rs.keys()\n",
    "    \n",
    "    Can also do this with one line of code:\n",
    "        df = pd.read_sql_query(\"SELECT * FROM Orders\", engine)\n",
    "    \n",
    "    Using INNER JOIN in Python(pandas)\n",
    "        from sqlalchemy import create_engine\n",
    "        import pandas as pd\n",
    "        engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "        df = pd.read_sql_query(\"SELECT OrderID, CompanyName FROM Orders INNER JOIN Customers on Orders.CustomerID = \n",
    "        Customers.CustomerID\", engine)\n",
    "        print(df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SCIENCE TOOLBOX - FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# defining a function\n",
    "def testsquare():                    # the function header\n",
    "    new_value = 4 ** 2               # the function body (indented)\n",
    "    print(new_value)\n",
    "testsquare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "16\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# function parameters\n",
    "def newtestsquare(value):\n",
    "    new_value = value ** 2\n",
    "    print(new_value)\n",
    "newtestsquare(3)\n",
    "newtestsquare(4)\n",
    "newtestsquare(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# return a value from a function using return\n",
    "def othertestsquare(value):\n",
    "    \"\"\"Return the square of a value.\"\"\"    # the docstring; describes what function does, serves as documentation\n",
    "    new_value = value ** 2\n",
    "    return new_value\n",
    "num = othertestsquare(4)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "# define shout with the parameter, word\n",
    "def shout(word):\n",
    "    \"\"\"Print a string with three exclamation marks\"\"\"\n",
    "    # concatenate the strings: shout_word\n",
    "    shout_word = word + '!!!'\n",
    "    # print shout_word\n",
    "    print(shout_word)\n",
    "# call shout with the string 'congratulations\n",
    "shout('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "# define shout with the parameter, word\n",
    "def shout(word):\n",
    "    \"\"\"Return a string with three exclamation marks\"\"\"\n",
    "    # concatenate the strings: shout_word\n",
    "    shout_word = word + '!!!'\n",
    "    # replace print with return\n",
    "    return(shout_word)\n",
    "# pass 'congratulations' to shout: yell\n",
    "yell = shout('congratulations')\n",
    "\n",
    "# print yell\n",
    "print(yell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# multiple function parameters\n",
    "def raise_to_power(value1, value2):\n",
    "    \"\"\"Raise value1 to the power of value2.\"\"\"\n",
    "    new_value = value1 ** value2\n",
    "    return new_value\n",
    "# then call the function with 2 arguments bc there are 2 parameters\n",
    "result = raise_to_power(2,3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# make functions return multiple values: tuples!\n",
    "# tuples: like a list(can contain multiple values, immutable -- can't modify values!)\n",
    "even_nums = (2, 4, 6) # tuples always have parentheses\n",
    "print(type(even_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# unpacking tuples! ... into several variables\n",
    "even_nums = (2, 4, 6)\n",
    "a, b, c = even_nums\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# can also access tuple elements like with a list\n",
    "even_nums = (2, 4, 6)\n",
    "print(even_nums[1])\n",
    "third_num = even_nums[2]\n",
    "print(third_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 9)\n"
     ]
    }
   ],
   "source": [
    "# let's now return multiple values\n",
    "def raise_both_nums(value1, value2):\n",
    "    \"\"\"Raise value1 to the power of value2 and vice versa.\"\"\"\n",
    "    \n",
    "    new_value1 = value1 ** value2\n",
    "    new_value2 = value2 ** value1\n",
    "    \n",
    "    new_tuple = (new_value1, new_value2)\n",
    "    \n",
    "    return new_tuple\n",
    "\n",
    "result = raise_both_nums(2,3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n",
      "you!!!\n"
     ]
    }
   ],
   "source": [
    "# define shout_all with parameters word1 and word2\n",
    "def shout_all(word1, word2):\n",
    "    \n",
    "    # concatenate word1 with '!!!': shout1\n",
    "    shout1 = word1 + '!!!'\n",
    "    \n",
    "    # concatenate word2 with '!!!': shout2\n",
    "    shout2 = word2 + '!!!'\n",
    "    \n",
    "    # construct a tuple with shout1 and shout2: shout_words\n",
    "    shout_words = shout1, shout2\n",
    "    \n",
    "    # return shout_words\n",
    "    return shout_words\n",
    "\n",
    "# pass 'congratulations' and 'you' to shout_all(): yell1, yell2\n",
    "yell1, yell2 = shout_all('congratulations', 'you')\n",
    "\n",
    "# print yell1 and yell2\n",
    "print(yell1)\n",
    "print(yell2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crash course on scope in functions\n",
    "# scope - part of the program where an object or name may be accessible\n",
    "\n",
    "new_val = 10                # global scope - defined in the main body of a script\n",
    "\n",
    "def cubed(value):\n",
    "    \"\"\"Returns the cube of a number.\"\"\"\n",
    "    new_val = value ** 3    # local scope - defined inside a function\n",
    "    return new_val\n",
    "\n",
    "cubed(3)\n",
    " \n",
    "# first look into local scope, then global, then built-in(like print)\n",
    "# built-in scope - names in the pre-defined built-ins module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "# nested functions\n",
    "\n",
    "def mod2plus5(x1, x2, x3):\n",
    "    \"\"\"Returns the remainder plus 5 of three values.\"\"\"\n",
    "    \n",
    "    def inner(x):\n",
    "        \"\"\"Returns the remainder plus 5 of a value.\"\"\"\n",
    "        return x % 2 + 5\n",
    "    \n",
    "    return (inner(x1), inner(x2), inner(x3))\n",
    "\n",
    "print(mod2plus5(1, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn how to\n",
    "    - import and locally save datasets from the web\n",
    "    - load datasets into pandas DataFrames\n",
    "    - make HTTP requests (GET requests)\n",
    "    - scrape web data such as HTML\n",
    "    - parse HTML into useful data (BeautifulSoup)\n",
    "    - use the urllib and requests packages\n",
    "\n",
    "The urllib package\n",
    "    - provides interface for fetching data across the web\n",
    "    - urlopen() -- accepts URLs instead of file names\n",
    "\n",
    "How to automate file download\n",
    "\n",
    "    from urllib.request import urlretrieve   # import function urlretrieve from request subpackage of urllib package\n",
    "    url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'   \n",
    "                                             # assign relevant url as a string to the variable url\n",
    "    urlretrive(url, 'winequality-white.csv') # use urlretrieve function to write contents of the url to a file\n",
    "    out: ('winequality-white.csv', <http.client.HTTPMessage at 0x103cf1128>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# practice from datacamp using red wine file\n",
    "from urllib.request import urlretrieve              \n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "urlretrieve(url, 'winequality-red.csv')      # save file locally\n",
    "\n",
    "df_rwine = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df_rwine.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11364aa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first column of df\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame.hist(df_rwine.iloc[:, 0:1])\n",
    "plt.xlabel('fixed acidity (g(tartaric acid)/dm$^3$)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['1700', '1900'])\n"
     ]
    }
   ],
   "source": [
    "# importing nonflat files from the web, excel example\n",
    "# get python dictionary with sheet names as keys and corresponding DataFrames as corresponding values\n",
    "\n",
    "url = 'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "\n",
    "xl = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "print(xl.keys())   # prints sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 country       1700\n",
      "0            Afghanistan  34.565000\n",
      "1  Akrotiri and Dhekelia  34.616667\n",
      "2                Albania  41.312000\n",
      "3                Algeria  36.720000\n",
      "4         American Samoa -14.307000\n"
     ]
    }
   ],
   "source": [
    "# print head of first sheet\n",
    "print(xl['1700'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP requests to import files from the web\n",
    "\n",
    "    URL = Uniform/Universal Resource Locator\n",
    "    Two Ingredients of URL\n",
    "        - protocol identifier such as http: or https\n",
    "        - resource name such as datacamp.com\n",
    "    \n",
    "    HTTP = HyperText Transfer Protocol, foundation of data communication for the web\n",
    "    HTTPS = more secure form of HTTP\n",
    "    \n",
    "    Each time go to a website, actually sending a HTTP request to a server and this request is known as GET request\n",
    "        - urlretrieve() performs a GET request\n",
    "        - use it get HTML data\n",
    "        - HTML = HyperText Markup Language\n",
    "        \n",
    "    from urllib.request import urlopen, Request\n",
    "    url = \"https://www.wikipedia.org/\"\n",
    "    request = Request(url)              # package GET request using Request()\n",
    "    response = urlopen(request)         # send request and catch response using urlopen()\n",
    "    html = response.read()              # apply read() to response to return HTML as string and store in variable html\n",
    "    response.close()                    # then close response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET requests using request\n",
    "\n",
    "    import requests\n",
    "    url = \"http://www.wikipedia.org/\"\n",
    "    r = requests.get(url)               # send the request and catch the response\n",
    "    text = r.text                       # apply text method to response which returns HTML as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "request = Request(url)                 # this packages the request\n",
    "response = urlopen(request)            # sends the request and catches the response\n",
    "\n",
    "print(type(response))                  # print datatype of response\n",
    "\n",
    "response.close()                       # polite to close response!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Web in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup\n",
    "\n",
    "    - parse and extract structured data from HTML\n",
    "    - make tag soup (structurally or syntactically incorrect html code) beautiful and extract information\n",
    "    \n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    url = 'https://www.crummy.com/software/BeautifulSoup/'\n",
    "    r = requests.get(url)\n",
    "    html_doc = r.text\n",
    "    soup = BeautifulSoup(html_doc)     # create beautifulsoup object from resulting html then prettify it\n",
    "    print(soup.prettify())             # prettified is indented in way would expect properly written html to be\n",
    "    \n",
    "\n",
    "Exploring Beautiful Soup\n",
    "    \n",
    "    print(soup.title)                  # extracts title\n",
    "    print(soup.get_text())             # extracts text\n",
    "    \n",
    "    for link in soup.find_all('a'):    # extracts url's of all the hyperlinks in the html\n",
    "        print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Guido's Personal Home Page\n",
      "  </title>\n",
      " </head>\n",
      " <body bgcolor=\"#FFFFFF\" text=\"#000000\">\n",
      "  <h1>\n",
      "   <a href=\"pics.html\">\n",
      "    <img border=\"0\" src=\"images/IMG_2192.jpg\"/>\n",
      "   </a>\n",
      "   Guido van Rossum - Personal Home Page\n",
      "  </h1>\n",
      "  <p>\n",
      "   <a href=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\">\n",
      "    <i>\n",
      "     \"Gawky and proud of it.\"\n",
      "    </i>\n",
      "   </a>\n",
      "  </p>\n",
      "  <h3>\n",
      "   <a href=\"http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\">\n",
      "    Who\n",
      "I Am\n",
      "   </a>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Read\n",
      "my\n",
      "   <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\n",
      "    \"King's\n",
      "Day Speech\"\n",
      "   </a>\n",
      "   for some inspiration.\n",
      "  </p>\n",
      "  <p>\n",
      "   I am the author of the\n",
      "   <a href=\"http://www.python.org\">\n",
      "    Python\n",
      "   </a>\n",
      "   programming language.  See also my\n",
      "   <a href=\"Resume.html\">\n",
      "    resume\n",
      "   </a>\n",
      "   and my\n",
      "   <a href=\"Publications.html\">\n",
      "    publications list\n",
      "   </a>\n",
      "   , a\n",
      "   <a href=\"bio.html\">\n",
      "    brief bio\n",
      "   </a>\n",
      "   , assorted\n",
      "   <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "    writings\n",
      "   </a>\n",
      "   ,\n",
      "   <a href=\"http://legacy.python.org/doc/essays/ppt/\">\n",
      "    presentations\n",
      "   </a>\n",
      "   and\n",
      "   <a href=\"interviews.html\">\n",
      "    interviews\n",
      "   </a>\n",
      "   (all about Python), some\n",
      "   <a href=\"pics.html\">\n",
      "    pictures of me\n",
      "   </a>\n",
      "   ,\n",
      "   <a href=\"http://neopythonic.blogspot.com\">\n",
      "    my new blog\n",
      "   </a>\n",
      "   , and\n",
      "my\n",
      "   <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">\n",
      "    old\n",
      "blog\n",
      "   </a>\n",
      "   on Artima.com.  I am\n",
      "   <a href=\"https://twitter.com/gvanrossum\">\n",
      "    @gvanrossum\n",
      "   </a>\n",
      "   on Twitter.  I\n",
      "also have\n",
      "a\n",
      "   <a href=\"https://plus.google.com/u/0/115212051037621986145/posts\">\n",
      "    G+\n",
      "profile\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <p>\n",
      "   In January 2013 I joined\n",
      "   <a href=\"http://www.dropbox.com\">\n",
      "    Dropbox\n",
      "   </a>\n",
      "   .  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my\n",
      "   <a href=\"Resume.html\">\n",
      "    resume\n",
      "   </a>\n",
      "   .)  I created Python while at CWI.\n",
      "  </p>\n",
      "  <h3>\n",
      "   How to Reach Me\n",
      "  </h3>\n",
      "  <p>\n",
      "   You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "   <a href=\"http://groups.google.com/groups?q=comp.lang.python\">\n",
      "    comp.lang.python\n",
      "   </a>\n",
      "   or\n",
      "   <a href=\"http://stackoverflow.com\">\n",
      "    StackOverflow\n",
      "   </a>\n",
      "   .  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "  </p>\n",
      "  <h3>\n",
      "   My Name\n",
      "  </h3>\n",
      "  <p>\n",
      "   My name often poses difficulties for Americans.\n",
      "  </p>\n",
      "  <p>\n",
      "   <b>\n",
      "    Pronunciation:\n",
      "   </b>\n",
      "   in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "   <a href=\"guido.au\">\n",
      "    sound clip\n",
      "   </a>\n",
      "   .)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "  </p>\n",
      "  <p>\n",
      "   <b>\n",
      "    Spelling:\n",
      "   </b>\n",
      "   my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "  </p>\n",
      "  <p>\n",
      "   <b>\n",
      "    Alphabetization:\n",
      "   </b>\n",
      "   in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "  </p>\n",
      "  <h3>\n",
      "   More Hyperlinks\n",
      "  </h3>\n",
      "  <ul>\n",
      "   <li>\n",
      "    Here's a collection of\n",
      "    <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "     essays\n",
      "    </a>\n",
      "    relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "    <p>\n",
      "    </p>\n",
      "   </li>\n",
      "   <li>\n",
      "    I own the official\n",
      "    <a href=\"images/license.jpg\">\n",
      "     <img align=\"center\" border=\"0\" height=\"75\" src=\"images/license_thumb.jpg\" width=\"100\"/>\n",
      "     Python license.\n",
      "    </a>\n",
      "    <p>\n",
      "    </p>\n",
      "   </li>\n",
      "  </ul>\n",
      "  <h3>\n",
      "   The Audio File Formats FAQ\n",
      "  </h3>\n",
      "  <p>\n",
      "   I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at\n",
      "   <a href=\"http://www.cnpbagwell.com/audio-faq\">\n",
      "    http://www.cnpbagwell.com/audio-faq\n",
      "   </a>\n",
      "   .  And here is a link to\n",
      "   <a href=\"http://sox.sourceforge.net/\">\n",
      "    SOX\n",
      "   </a>\n",
      "   , to which I contributed\n",
      "some early code.\n",
      "  </p>\n",
      "  <hr/>\n",
      "  <a href=\"images/internetdog.gif\">\n",
      "   \"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "  </a>\n",
      "  <hr/>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.python.org/~guido/'\n",
    "r = requests.get(url)                 # package request, send request and catch response r\n",
    "html_doc = r.text                     # extracts the response as html\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")        # create BeautifulSoup object from HTML\n",
    "pretty_soup = soup.prettify()         # prettify the BeautifulSoup object\n",
    "\n",
    "print(pretty_soup)                    # print the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "\n",
      "\n",
      "Guido's Personal Home Page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Guido van Rossum - Personal Home Page\n",
      "\"Gawky and proud of it.\"\n",
      "Who\n",
      "I Am\n",
      "Read\n",
      "my \"King's\n",
      "Day Speech\" for some inspiration.\n",
      "\n",
      "I am the author of the Python\n",
      "programming language.  See also my resume\n",
      "and my publications list, a brief bio, assorted writings, presentations and interviews (all about Python), some\n",
      "pictures of me,\n",
      "my new blog, and\n",
      "my old\n",
      "blog on Artima.com.  I am\n",
      "@gvanrossum on Twitter.  I\n",
      "also have\n",
      "a G+\n",
      "profile.\n",
      "\n",
      "In January 2013 I joined\n",
      "Dropbox.  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my resume.)  I created Python while at CWI.\n",
      "\n",
      "How to Reach Me\n",
      "You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "comp.lang.python or\n",
      "StackOverflow.  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "\n",
      "My Name\n",
      "My name often poses difficulties for Americans.\n",
      "\n",
      "Pronunciation: in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "sound clip.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "Spelling: my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "Alphabetization: in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "More Hyperlinks\n",
      "\n",
      "Here's a collection of essays relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "I own the official \n",
      "Python license.\n",
      "\n",
      "The Audio File Formats FAQ\n",
      "I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at http://www.cnpbagwell.com/audio-faq.  And here is a link to\n",
      "SOX, to which I contributed\n",
      "some early code.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guido_title = soup.title              # get title of webpage\n",
    "guido_text = soup.get_text()          # get text of webpage\n",
    "\n",
    "print(guido_title)\n",
    "print(guido_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "https://plus.google.com/u/0/115212051037621986145/posts\n",
      "http://www.dropbox.com\n",
      "Resume.html\n",
      "http://groups.google.com/groups?q=comp.lang.python\n",
      "http://stackoverflow.com\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# find all 'a' tags (which define hyperlinks)\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to APIs and JSONs\n",
    "\n",
    "### APIs - Application Programming Interface\n",
    "    - set of protocols and routines for building and interacting with software applications\n",
    "    - we'll use OMDb API (The Open Movie Database) and Twitter API to pull data from both applications\n",
    "\n",
    "### JSONs - JavaScript Object Notation\n",
    "    - file format used as standard form for transfering data through APIs\n",
    "    - real-time server-to-browser communication\n",
    "    - when loading JSONs into python, natural to store them into dict\n",
    "        - keys will always be strings\n",
    "        - values can be strings, integers, arrays, or objects (object could even be JSON, then have nested JSONs) \n",
    "\n",
    "Loading JSONs in Python\n",
    "\n",
    "    import json\n",
    "    with open('snakes.json', 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    type(json_data)\n",
    "        <output: dict>                          # python imports it as dictionary\n",
    "    \n",
    "    for key, value in json_data.items():        # will print key-value pairs to console\n",
    "        print(key + ':', value)\n",
    "    \n",
    "    for k in json_data.keys():\n",
    "        print(k + ':', json_data[k]             # another way to print key-value pairs\n",
    "                                                # recall that to access value in dict use syntax dictionary[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs and Interacting with the World Wide Web\n",
    "\n",
    "API - bunch of code that allows two software programs to communicate with each other\n",
    "    - example, if wanted to stream Twitter data, would use Twitter API\n",
    "\n",
    "Connecting to an API in Python\n",
    "\n",
    "    import requests\n",
    "    url = 'http://www.omdbapi.com/?t=hackers'\n",
    "    r = requests.get(url)\n",
    "    json_data = r.json()                       \n",
    "    \n",
    "    # cool aspect of requests package is that response object r has associated method json which is json decoder for when dealing with json data\n",
    "    \n",
    "    for key, value in json_data.items():\n",
    "        print(key + ':', value)\n",
    "        \n",
    "What was that URL?\n",
    "    \n",
    "    http - making an http request\n",
    "    www.omdbapi.com - querying the OMDb API\n",
    "    ?t=hackers\n",
    "        - this string that begins with ? is a Query String\n",
    "        - Query Strings are parts of URLs that don't fit into conventional heirarchical path structure\n",
    "        - what follows ? in Query String is the query we are making to OMDb API\n",
    "        - t=hackers returns data for a movie with title (t) 'Hackers'\n",
    "        - we knew this was how to perform such a query from the documentation on the OMDb API's home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Title\":\"The Social Network\",\"Year\":\"2010\",\"Rated\":\"PG-13\",\"Released\":\"01 Oct 2010\",\"Runtime\":\"120 min\",\"Genre\":\"Biography, Drama\",\"Director\":\"David Fincher\",\"Writer\":\"Aaron Sorkin (screenplay), Ben Mezrich (book)\",\"Actors\":\"Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\",\"Plot\":\"Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\",\"Language\":\"English, French\",\"Country\":\"USA\",\"Awards\":\"Won 3 Oscars. Another 165 wins & 168 nominations.\",\"Poster\":\"https://ia.media-imdb.com/images/M/MV5BMTM2ODk0NDAwMF5BMl5BanBnXkFtZTcwNTM1MDc2Mw@@._V1_SX300.jpg\",\"Ratings\":[{\"Source\":\"Internet Movie Database\",\"Value\":\"7.7/10\"},{\"Source\":\"Rotten Tomatoes\",\"Value\":\"96%\"},{\"Source\":\"Metacritic\",\"Value\":\"95/100\"}],\"Metascore\":\"95\",\"imdbRating\":\"7.7\",\"imdbVotes\":\"540,512\",\"imdbID\":\"tt1285016\",\"Type\":\"movie\",\"DVD\":\"11 Jan 2011\",\"BoxOffice\":\"$96,400,000\",\"Production\":\"Columbia Pictures\",\"Website\":\"http://www.thesocialnetwork-movie.com/\",\"Response\":\"True\"}\n"
     ]
    }
   ],
   "source": [
    "# recently OMDb changed their API, now also have to specify an API key\n",
    "# add another argument to API key, apikey=ff21610b\n",
    "# looks like ?apikey=ff21610b&t=social+network\n",
    "\n",
    "# import requests ... already imported from before\n",
    "\n",
    "url = 'http://www.omdbapi.com/?apikey=ff21610b&t=social+network'\n",
    "r = requests.get(url)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Social Network\n",
      "Year: 2010\n",
      "Rated: PG-13\n",
      "Released: 01 Oct 2010\n",
      "Runtime: 120 min\n",
      "Genre: Biography, Drama\n",
      "Director: David Fincher\n",
      "Writer: Aaron Sorkin (screenplay), Ben Mezrich (book)\n",
      "Actors: Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\n",
      "Plot: Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\n",
      "Language: English, French\n",
      "Country: USA\n",
      "Awards: Won 3 Oscars. Another 165 wins & 168 nominations.\n",
      "Poster: https://ia.media-imdb.com/images/M/MV5BMTM2ODk0NDAwMF5BMl5BanBnXkFtZTcwNTM1MDc2Mw@@._V1_SX300.jpg\n",
      "Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.7/10'}, {'Source': 'Rotten Tomatoes', 'Value': '96%'}, {'Source': 'Metacritic', 'Value': '95/100'}]\n",
      "Metascore: 95\n",
      "imdbRating: 7.7\n",
      "imdbVotes: 540,512\n",
      "imdbID: tt1285016\n",
      "Type: movie\n",
      "DVD: 11 Jan 2011\n",
      "BoxOffice: $96,400,000\n",
      "Production: Columbia Pictures\n",
      "Website: http://www.thesocialnetwork-movie.com/\n",
      "Response: True\n"
     ]
    }
   ],
   "source": [
    "# now decode JSON data into a dictionary\n",
    "json_data = r.json()\n",
    "\n",
    "# print each key-value pair\n",
    "for k in json_data.keys():\n",
    "    print(k + ':', json_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><b>Pizza</b> is a traditional Italian dish consisting of a yeasted flatbread typically topped with tomato sauce and cheese and baked in an oven. It can also be topped with additional vegetables, meats, and condiments, and can be made without cheese.</p>\n",
      "<p>The term <i>pizza</i> was first recorded in the 10th century, in a Latin manuscript from the Southern Italian town of Gaeta in Lazio, on the border with Campania. Modern pizza was invented in Naples, and the dish and its variants have since become popular and common in many areas of the world. In 2009, upon Italy's request, Neapolitan pizza was registered with the European Union as a Traditional Speciality Guaranteed dish. The <i>Associazione Verace Pizza Napoletana</i> (True Neapolitan Pizza Association), a non-profit organization founded in 1984 with headquarters in Naples, aims to \"promote and protect... the true Neapolitan pizza\".</p>\n",
      "<p>Pizza is one of the most popular foods in the world and a common fast food item in Europe and North America. Many independent or chain restaurants, cafes, and fast food outlets offer pizza. Restaurants or chains specializing in pizza are pizzerias. Pizza delivery is common in some parts of the world.</p>\n",
      "<p>Pizza is sold fresh or frozen, either whole or in portions. Various types of ovens are used to cook them and many varieties exist. Several similar dishes are prepared from ingredients commonly used in pizza preparation, such as calzone and stromboli. In the United States, pizza is usually eaten out of hand after dividing into slices from a large pizza or small pizzetta as a whole. In Italy, pizza is eaten with a fork and knife in restaurants, but is also sold to take away and eaten out of hand. Frozen pizza became popular in the late 20th century.</p>\n",
      "<p></p>\n",
      "\n",
      "<p></p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# also practice with Wikipedia API\n",
    "\n",
    "# import package, but again already imported\n",
    "\n",
    "url = 'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n",
    "r_wiki = requests.get(url)\n",
    "json_wikidata = r_wiki.json()\n",
    "\n",
    "# print Wikipedia page extract from Wiki's Pizza page\n",
    "pizza_extract = json_wikidata['query']['pages']['24768']['extract']\n",
    "print(pizza_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API and Authentication\n",
    "    - learn how to stream data from Twitter API\n",
    "    - how to filter incoming tweets for keywords\n",
    "    - about API Authentication and OAuth\n",
    "    - how to use the Tweepy Python package\n",
    "\n",
    "Access the Twitter API - must have an account!\n",
    "    - login to Twitter Apps and create new app (https://apps.twitter.com/)\n",
    "    - under Keys and Access Tokens, need:\n",
    "        - API Key\n",
    "        - API Secret\n",
    "        - Access Token\n",
    "        - Access Token Secret\n",
    "    - going to use Streaming API\n",
    "    - Tweets are returned a JSONs\n",
    "    \n",
    "    import tweepy, json\n",
    "    \n",
    "    access_token = \"...\"\n",
    "    access_token_secret = \"...\"\n",
    "    consumer_key = \"...\"\n",
    "    consumer_secret = \"...\"\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    \n",
    "    class MyStreamListener(tweepy.StreamListener):            # define a tweet listener\n",
    "        def __init__(self, api=none)\n",
    "            super(MyStreamListener, self).__init__()\n",
    "            self.num_tweets = 0\n",
    "            self.file = open(\"tweets.txt\", \"w\")               # tweet listener creates file tweets.txt\n",
    "            \n",
    "        def on_status(self, status):\n",
    "            tweet = status._json\n",
    "            self.file.write(json.dumps(tweet) + '\\n')         # collects streaming tweets, writes to file tweets.txt\n",
    "            tweet_list.append(status)\n",
    "            self.num_tweets += 1\n",
    "            if self.num_tweets < 100:                         # once 100 tweets streamed, listener closes file/stops\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            self.file.close()\n",
    "\n",
    "    \n",
    "    Using Tweepy # create streaming object and authenticate\n",
    "    l = MyStreamListener()\n",
    "    stream = tweepy.Stream(auth, l)\n",
    "    \n",
    "    stream.filter(track=['apples', 'oranges']) # this line filters Twitter Streams to capture data by keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import tweepy, json\n",
    "\n",
    "access_token = \"248944628-ugVn2o67KUmPp7c0DGTvXZ2IJFmOct0dXttV9bAB\"\n",
    "access_token_secret = \"dZ1xfm7gu3r8SiHyubcC0lhpv5wWVnoAyCYclQUdXh3dN\"\n",
    "consumer_key = \"DcbOYOJ7X9MYuXL4rjqczfEVp\"\n",
    "consumer_secret = \"9tqNXQankRrvfLHDWfVC6tYvUtlIwm6Df7Rgh1lN5JhkIg1SCp\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):            # define a tweet listener\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")               # tweet listener creates file tweets.txt\n",
    "            \n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write(json.dumps(tweet) + '\\n')         # collects streaming tweets, writes to file tweets.txt\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 500:                         # once 500 tweets streamed, listener closes file/stops\n",
    "            return True\n",
    "        else:\n",
    "            self.file.close()\n",
    "            return False\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "    \n",
    "# initialize Stream Listener\n",
    "l = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, l)\n",
    "    \n",
    "stream.filter(track=['curry', 'harden', 'warriors', 'rockets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'extended_entities', 'favorited', 'retweeted', 'possibly_sensitive', 'filter_level', 'lang', 'timestamp_ms'])\n"
     ]
    }
   ],
   "source": [
    "# string of path to file: tweets_data_path\n",
    "tweets_data_path = 'tweets.txt'\n",
    "\n",
    "# initialize empty list to store tweets: tweets_data\n",
    "tweets_data = []\n",
    "\n",
    "# open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# read in tweets and store in list: tweets_data\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# print keys of first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text lang\n",
      "0  RT @timelesssports_: (2007) Steph Curry gettin...   en\n",
      "1  When I don't get to watch the game Curry goes ...   en\n",
      "2  @bonnermvp_ foda mesmo foi o  lebrao e o kyri...   pt\n",
      "3          RT @DwyaneWade:  https://t.co/rF8cQaLwtG  und\n",
      "4                               Rockets done for smh   en\n"
     ]
    }
   ],
   "source": [
    "# build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns=['text', 'lang'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_in_text(word, tweet):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, tweet)\n",
    "    \n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# initialize list to store tweet counts\n",
    "[curry, harden, warriors, rockets] = [0, 0, 0, 0]\n",
    "\n",
    "# interate through df, counting number of tweets in which either Lindor or smile is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    curry += word_in_text('curry', row['text'])\n",
    "    harden += word_in_text('harden', row['text'])\n",
    "    warriors += word_in_text('warriors', row['text'])\n",
    "    rockets += word_in_text('rockets', row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a741780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# create list of labels: wcf18\n",
    "wcf18 = ['curry', 'harden', 'warriors', 'rockets']\n",
    "\n",
    "# plot histogram\n",
    "ax = sns.barplot(wcf18, [curry, harden, warriors, rockets])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
